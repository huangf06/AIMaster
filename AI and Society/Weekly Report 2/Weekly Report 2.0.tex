\documentclass[11pt]{article}
\usepackage{xeCJK}

\title{AI and Society: 数据垄数和不平等}

\begin{document}
\maketitle

\section{Introduction}

随着人工智能和自动化的快速发展，技术正在日益深刻地重塑我们的生活。本篇报告针对目前日益迫切需要解决的两个问题进行了研讨：数据垄数和不平等问题。

第一个问题，科技巨头已经肉眼可见地越来越多地影响人们的生活，那么人们对科技公司的权力担忧是真实反映实际情况的吗，还是仅仅是人们过度担忧的浮夸之词？如果这种权力的危胁真实存在，那它又是如何形成的，如今的监管努力是否行走在正确的方向，还是有意无意地忽视了问题的关键所在？

第二个问题，人工智能对未来世界势必造成的影响程度已经越来越成为共识，那么在未来的世界，它到底是会进一步加剧不平等，还是能够被有效地监管和使用，使科技的力量真正增进全人类的福利？为此我们需要做些什么？

\section{Part 1: 数据垄断}

\subsection{媒体观点}

正如techpolicy的一篇文章标题所写的那样，垄断权力是人工智能辩论中房间里的大象。数据垄断的问题日益地浮出水面，越发激烈地引起人们的争论，正在成为一个不可否认不容忽视的问题。

数据垄断的权力究竟从何而来？媒体们普遍给出的答案是数据。Politico的文章指出，“从头开始训练一个新的人工智能系统成本高昂，只有少数公司——主要是世界科技巨头——能够获得足够的数据来做好它。” 高质量的数据正是这些科技巨头们的关键战略优势。说到人工智能，更好的数据总是会赢。forbes的文章也指出，亚马逊和苹果通过详细访问用户数据来建立垄断，这反过来又使他们能够为各自的生态系统构建最好的人工智能推荐系统。此外，facebook和google在用户和首选内容之间的网络图上建立起了垄断。不难看出，无论谁拥有最大的网络图，都能最好地理解网络，并且最容易地朝着他们喜欢的方向影响它。

那么只有少数玩家在顶部有什么问题呢？

首先，是一个经济超级集中和企业拥有政权权力的未来。
theasset的Eric Posner文章指出，如果人工智能兑现其承诺，并成为经济每个部门的命脉，我们可以期待经济集中和企业政治权力的未来，这使之前的任何东西都相形见绌。少数玩家之间的勾结和协调将使这一结果几乎不可避免。大型科技公司们将整体经济中的影响力现在在整个经济中的影响力与银行相似。通过访问数据，他们比银行更了解消费者和商业行为，并对它施加了更大的控制权。他们为整个经济的企业提供重要的投入，以及为几乎所有消费者提供产品和服务。从来没有一家银行有过这样的影响力。
另外地，politico的文章另外也指出了一些其他问题，it creates a much less robust foundation for a major growth area in the tech economy; privately developed models still have problems with biased outputs. 

那么面对这样的问题，政策制定者能够做些什么？

一个潜在的政府解决方案是创建一个公共资源，使研究人员能够了解这项技术的新兴能力和局限性。在人工智能中，这看起来像是构建一个公共资助的大型语言模型，其中包含伴随的数据集和计算资源，供研究人员使用。politico的文章为我们提供了一个看上去合理可行的思路。

\subsection{学术观点}

Catherine Mulligan在她的Datalism and Data Monopolies in the Era of A.I.: A Research Agenda论文中指出，经济和社会系统各个部分日益使用数据，这正在创造一种新形式的垄断——数据垄断。而且使用这些策略的公司——数据主义者——正在挑战现有的垄断资本理论(MCT)中使用的定义。数据主义者追求对数据的垄断控制，以供养他们的生产过程，而这些生产过程越来越多地由算法和人工智能（AI）控制。这些生产过程使用关于人类和人类创造性产出的信息作为输入，但不把这些人类归为员工，因此他们的劳动没有得到报酬和或认可。

Mason Marks在Biosupremacy: Big Data, Antitrust, and Monopolistic Power Over Human Behavior这篇文章中提出生物权力这一概念，即测量和修改人群行为以改变社会规范的能力。他认为，新世纪以来，科技公司在对人类事务的影响上已变得强大到相当于许多政府。而他们的力量来源于他们在家庭、工作场所、学校和公共空间的设备收集的数据。当与人工智能配对时，这些设备形成了一个庞大的监控网络，将人们分成越来越具体的健康、性别、宗教和其他类别相关的分类。同时，利用通过监控获得的智能来操纵人们的行为，通过个性化新闻、针对性广告、暗模式以及其他形式的强制性选择架构来推动他们。这两个监控和控制的网络共同形成一个全球性的数字全景监狱。而少数公司正在争夺生物权力的主导份额，以实现生物霸权，对人类行为的垄断力量。文章提示我们反垄断监管机构应该扩大他们对消费者福利的概念，重新启动集团合并控制，停止集中生物权力的合并，禁止使用暗模式，并要求数据孤岛，阻止跨市场数据流动。

Daniel Macintosh在How Digital Monopolies Arise and why they have power and influence文章中，过去以来，知识产权一直被怀疑是推动数字平台垄断化的因素。但事实上，知识产权被错怪了。大型科技公司形成垄断的核心原因是数据在正向反馈循环中所起的网络效应。处理网络效应的问题一直很困难。过去，竞争法律是解决问题的通用方法。然而，这种法规因为数据并不完全适合传统的经济模型而被证明大多数无效。另一个传统的替代方案是消费者法，但其主要关注的是个人隐私，而不是垄断权力。而法律无效的原因在于它们没有处理大型科技垄断的某些有害效应，因为数据垄断本质上与其他商品和服务不同，因为数据是信息。所以，重新构想的竞争和消费者法规可能会防止价格膨胀和严苛的隐私政策，但这些政策可能不会解决大型科技数据垄断的更迫切问题。

小结：

整体而言，对于数据垄断问题的存在和影响力之上，媒体和学界基本持一致的观点，并学界对这种权力形成的原理给出了更深入的研究和解释。对于如何解决这个问题上，有学界观点提示我们现在的监管努力可能并没有能真正有效地制衡垄断权力。
\section{第二部分：不平等}

\subsection{媒体观点}

来自technologyreview的文章，经济学家brynjolfsson说，简单的自动化在产生价值的同时，也可以成为导致收入和财富不平等加剧的途径。他认为，过度关注人工智能，这让大多数人工资下降。它放大了少数拥有和控制这些技术的人的市场力量，是许多美国人平均实际工资下降，而大量亿万富翁崛起的最大解释。而且今时不同往日，以前技术转变产生的新工作比摧毁的多，但现在一般技术对提高生力或创造新的商业机会几乎无所作为。怨恨在许多人中酝酿，因为人们认为好处会惠及少数繁荣城市的精英。

诺贝尔经济学奖约瑟夫·E也发出警告，不受约束的资本主义，不受约束的创新，不会带来我们社会的普遍福祉。人工智能已经使数千个工作岗位消失，并最终可能导致数亿的自动化。如果不加以控制，这种劳动力中断可能会进一步将财富集中在公司手中，使工人的权力比以往任何时候都少。我们创造了一个工人没有太多议价能力的制度。在这种世界中，人工智能可能是雇主的盟友，进一步削弱工人的讨价还价能力，并进一步加剧不平等。

根据卫报的报道，国际货币基金组织负责人克里斯塔利娜·格奥尔基耶娃提醒，人工智能将影响全球40\%的工作岗位，呼吁各国建立社会安全网以减轻对弱势工人的影响是“至关重要的”。

而参加达沃斯论坛的经济学家们，预计人工智能将不平等地影响世界经济。其中94\%的受访经济学家预计人工智能将在未来五年内从根本上提高高收入经济体的生产力，但只有53\%的人预测对低收入经济体会有类似的影响。而87\%的经济学家预测，随着地缘政治的发展，人工智能的影响预计将加剧全球经济的波动。57\%还预计，这些情况将在未来三年内加剧不平等并扩大南北鸿沟。

\subsection{学界观点}

学界的研究也支持媒体上述关于随着技术发展不平等在加剧扩大的观点。Arjun Goyal, Ranjan Aneja在他们的论文Artificial intelligence and income inequality: Do technological changes and worker's position matter? 中试图了解收入不平等是如何随着技术的变化而加剧的。该研究还调查了人工智能等技术如何（直接或间接）影响工人的工作位置和工作流程。对该研究的分析基于自动化和基尼系数的数据。研究发现，人工智能和收入分配之间的关系一直被认为是负面的，这就是本研究中观察到的，它直接影响收入和就业的分配。由于自动化，中低技能工作正在下降，失业率正在上升，中高技能劳动力之间的收入差距正在进一步扩大。而且发展中国家的基尼系数要高于发达国家，这表明发展中国家的收入不平等高于发达国家。

关于如何尝试解决不平等的问题，学界呼吁对人工智能的研究引入社会学方法。在Kelly Joyce的一篇文章指出，虽然当代人工智能科学家确实认识到社会的存在，并使用多种策略在人工智能中解释它。然而，这些人工智能从业者主导的努力通常无法认识到社会生活的全部复杂性，特别是当与社会学家提供的批判性见解相抗时。人工智能从业者倾向于将人类数据定位为单一、直接和稳定的方式，从而将社会结合起来，错过了充分考虑权力动态、系统性歧视和社会不平等如何促进社会类别意义的机会。
而同时社会学的深刻结构性方法也与强调个人选择的方法形成鲜明对比。当科技界的工程师和伦理学家强调消除个人层面的人类偏见和改善敏感性培训。然而，社会学的研究却表明，偏见不是在个人内部自由浮动的，而是植根于顽固的社会机构中。换句话说，通过更好地培训人工智能从业者，并不容易实现透明度和公平性。


在Laura Sartori和Andreas Theodorou的A sociotechnical perspective for the future of AI: narratives, inequalities, and human control文章指出：
人工智能系统是我们道德机构的延伸（Bryson，2017年；Theodorou，2020年）以及我们作为属于社会、经济和政治结构（例如社会阶层）的社会行为者自然体现的不平等。作为Caliskan等人。（2017年）表明，人工智能的使用不仅带来了自动化和放大不平等的风险，而且还提供了利用人工智能透明度的机会，以更好地识别这些偏见，希望克服它们，或至少抵消与社会的平衡。
If we consider AI as a sociotechnical system, we are to include all participants in the process of construction in a co-creation approach. Hence, research could also shed light on the legitimization mechanisms underlying the relationship between social and artificial agents. Since technology is not any magic, the relevance of narratives in shaping current realities is a strong call for citizens—with their perceptions and beliefs—to sit at the table for the future of AI.


在Mike Zajko的Artificial intelligence, algorithms, and social inequality: Sociological contributions to contemporary debates这篇文章里指出，sociologists can help assert agency over new technologies through three kinds of actions: (1) critique and the politics of refusal; (2) fighting inequality through technology; and (3) governance of algorithms. 文章发现，社会不平等是真实的，这种不平等始终出现在用于通过机器学习训练算法的数据中，以及这些系统的输出中。而任何寻求解决方案的尝试本质上都是政治性的，避免这个问题或将其视为数据科学的范围外都相当于保守的取向。而在关于自动化和人工智能的讨论中，人类代理的丧失是一个反复出现的担忧。而结构性不平等长期以来剥夺了边缘化群体的某些形式的代理。批判是一种有价值的社会学论证模式，可以分析“算法如何再现和加强现有结构”，将新技术置于“更广泛的政治、种族、文化和经济结构”中。通过算法治理为配置、工程和构建社会提供新方法。应用社会学可能有助于引导这些社会技术系统解决更大、相互关联和系统性问题，包括各种不平等及其后果。

结论：学术界和媒体界在关于技术加剧不平等上没有太多争议，并且尝试了从社会学视角提出解决不平等问题的途径。

\section{结论}

数据垄断的问题确定存在，科技巨头们通过监控网络收集数据，并通过控制网络投放影响，垄断了生物权力，并且人类和人类创造性产出的信息被无偿使用，导致了新时代的垄断资本。而且由于数据垄断同过往的产品服务竞争不同，很难被竞争法规监管，而消费者法则更多关注隐私，而对垄断权力制衡作用有限。

不平等的问题确实随着人工智能和自动化的技术发展而加剧。而解决这些不平等问题需要更多社会学的考量，人工智能的发展需要与社会学结合起来，充分考虑权力动态、系统性歧视和社会不平等。而结构性不平等的根源在于长期以来边缘化群体的某些代理被剥夺，社会学者可以通过批判和拒绝政治，fighting inequality through technology; and (3) governance of algorithms来解决人工代理的丧失问题，从而促进解决结构性不平等的问题。


\end{document}
